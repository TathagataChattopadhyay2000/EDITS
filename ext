<!-- badges: start -->
[![Linux](https://github.com/Boehringer-Ingelheim/bhmbasket/actions/workflows/linux.yml/badge.svg?branch=test)](https://github.com/Boehringer-Ingelheim/bhmbasket/actions/workflows/linux.yml)
[![Windows](https://github.com/Boehringer-Ingelheim/bhmbasket/actions/workflows/windows.yml/badge.svg?branch=test)](https://github.com/Boehringer-Ingelheim/bhmbasket/actions/workflows/windows.yml)
[![macOS](https://github.com/Boehringer-Ingelheim/bhmbasket/actions/workflows/macos.yml/badge.svg?branch=test)](https://github.com/Boehringer-Ingelheim/bhmbasket/actions/workflows/macos.yml)
[![Codecov test coverage](https://codecov.io/gh/Boehringer-Ingelheim/bhmbasket/branch/test/graph/badge.svg)](https://app.codecov.io/gh/Boehringer-Ingelheim/bhmbasket?branch=test)
<!-- badges: end -->


# Tests for simulateScenarios --------------------------------------------------

test_that("simulateScenarios has correct structure", {
  
  # example
  n_subjects <- c(10, 20, 30)
  rr_1 <- c(0.1, 0.1, 0.1)   
  rr_2 <- c(0.9, 0.9, 0.9)
  
  # TODO: historical data scenario - DONE
  rr_3 <- c(0.9, 0.9, 1)
  rr_4 <- c(0.9, 0.9, 0)
  
  rr_5 <- c(0.9, 0.9, 1.1) # expect error
  
  scenarios <- simulateScenarios(
    n_subjects_list     = list(n_subjects, n_subjects, n_subjects, n_subjects),
    response_rates_list = list(rr_1, rr_2, rr_3, rr_4),
    scenario_numbers    = c(1, 2, 3, 4),
    n_trials            = 25
  )
  
  expect_s3_class(scenarios, "scenario_list")
  
  expect_equal(names(scenarios), paste0("scenario_", 1:4))
  
  s1 <- scenarios[[1]]
  s3 <- scenarios[[3]]
  
  # structure
  expect_true(is.matrix(s1$n_subjects))
  
  expect_true(is.matrix(s1$response_rates))
  
  expect_equal(s1$n_trials, 25)
  
  # CHECK 1st TODO
  hist_cols <- which(rr_3 <= 0 | rr_3 >= 1)
  
  expect_true(all(apply(s3$n_responders[, hist_cols, drop = FALSE], 2, function(x) length(unique(x)) == 1)))
  
  
  # dimensions and names
  expect_equal(ncol(s1$n_subjects), length(n_subjects))
  
  expect_equal(ncol(s1$response_rates), length(n_subjects))
  
  expect_equal(
    
    colnames(s1$n_subjects),
    paste0("n_", seq_len(length(n_subjects)))
    
  )
  
  expect_equal(
    
    colnames(s1$n_responders),
    paste0("r_", seq_len(length(n_subjects)))
    
  )
  
  expect_equal(
    
    colnames(s1$response_rates),
    paste0("rr_", seq_len(length(n_subjects)))
    
  )
  
  expect_error(
    simulateScenarios(
      n_subjects_list     = list(n_subjects),
      response_rates_list = list(rr_5),
      scenario_numbers    = 5,
      n_trials            = 5
    )
  )
  
})


test_that("simulateScenarios has no mismatch and gives appropriate error messages", {
  
  n_subjects <- list(c(10, 20, 30))
  rr_1       <- c(0.1, 0.1, 0.1)
  rr_ok      <- c(0.2, 0.3, 0.4)
  
  #  returns TRUE if 5L is a valid integer â‰¥ 1. Sanity check
  expect_true(checkmate::test_int(5L, lower = 1))
  
  # --- keep: missing required args (do not remove) ---
  expect_error(simulateScenarios(n_subjects_list = n_subjects),
               "response_rates_list")
  
  expect_error(simulateScenarios(response_rates_list = list(rr_1)),
               "n_subjects_list")
  
  # vector n_subjects_list is recycled to list (positive case retained)
  expect_s3_class(
    
    simulateScenarios(
      n_subjects_list     = c(10, 20, 30),          # vector, not list
      response_rates_list = list(rr_1, rr_1),
      n_trials            = 2
    ),
    "scenario_list"
    
  )
  
  # --- focus: ALL invalid numeric cases for n_trials ---
  invalid_trials <- list(
    
    zero     = 0L,
    negative = -1L,
    nonint   = 2.5,
    na       = NA_integer_,
    nan      = NaN,
    inf      = Inf,
    ninf     = -Inf,
    length2  = c(2L, 3L)
    
  )
  
  for (case in invalid_trials) {
    
    expect_error(
      simulateScenarios(
        n_subjects_list     = list(c(10,20,30)),
        response_rates_list = list(rr_1),
        n_trials            = case
      ),
      "n_trials",
      info = paste("invalid n_trials case:", case)
    )
    
  }
  
  # --- keep: list checks (do not remove) ---
  # list length mismatch
  expect_error(
    
    simulateScenarios(
      n_subjects_list     = list(c(10, 20, 30)),
      response_rates_list = list(rr_1, rr_1)
    ),
    "same length"
    
  )
  
  expect_error(
    
    simulateScenarios(
      n_subjects_list     = list(c(10, 20, 30), c(10, 20, 30)),
      response_rates_list = list(c(0.1, 0.2, 0.3), c(0.2, 0.3, 0.4)),
      scenario_numbers    = c(1)
    ),
    "scenario_numbers"
    
  )
  
  expect_error(
    
    simulateScenarios(
      n_subjects_list     = list(10),          # 1 cohort
      response_rates_list = list(0.1),         # 1 cohort
      n_trials            = 2
    ),
    "at least 2 cohorts"
    
  )
  
  expect_error(
    
    simulateScenarios(
      n_subjects_list     = list(c(10, 20), c(10, 20)),   # 2 cohorts each
      response_rates_list = list(c(0.1, 0.2), 0.3),    # 2 vs 1 cohorts
      n_trials            = 2
    ),
    "same number of cohorts"
    
  )
  
  expect_error(
    
    simulateScenarios(
      n_subjects_list     = list(c(10, 20), 10),   # 2 vs 1 cohorts each
      response_rates_list = list(c(0.1, 0.2), c(0.1, 0.3)),    # 2 cohorts each
      n_trials            = 2
    ),
    "same number of cohorts"
    
  )
  
  # --- keep: uses .GlobalEnv$n_trials when n_trials missing ---
  old <- if (exists("n_trials", .GlobalEnv)) get("n_trials", .GlobalEnv) else NULL
  
  on.exit({
    if (is.null(old)) rm(list = "n_trials", envir = .GlobalEnv) else assign("n_trials", old, .GlobalEnv)
  }, add = TRUE)
  assign("n_trials", 7L, envir = .GlobalEnv)
  
  out <- simulateScenarios(
    
    n_subjects_list     = list(c(10,20,30)),
    response_rates_list = list(rr_ok)
    # n_trials intentionally omitted
    
  )
  
  expect_equal(out[[1]]$n_trials, 7L)
  
})

#  Tests for saveScenarios -----------------------------------------------------
#  TODO Read in the file, the rds file, have a test what should be in the file is 
# indeed in the file.

test_that("saveScenarios saves files correctly", {
  # Create mock scenario_list
  mock_scenario <- function(num) {
    structure(list(scenario_number = num, data = paste("Scenario", num)),
              class = "scenario")
  }
  scenario_list <- list(mock_scenario(1), mock_scenario(2))
  class(scenario_list) <- "scenario_list"
  
  # Create temp directory
  temp_dir <- tempfile()
  dir.create(temp_dir)
  
  # Run function
  result <- saveScenarios(scenario_list, save_path = temp_dir)
  
  # Check that files are created
  expect_true(file.exists(file.path(temp_dir, "scenario_data_1.rds")))
  expect_true(file.exists(file.path(temp_dir, "scenario_data_2.rds")))
  
  # Check return value
  expect_equal(result$scenario_numbers, c(1, 2))
  expect_equal(result$path, temp_dir)
  
  # Clean up 
  unlink(temp_dir, recursive = TRUE)
})


test_that("saveScenarios creates directory when save_path does not exist", {
  temp_dir <- tempfile()                 # path that does NOT exist yet
  expect_false(dir.exists(temp_dir))     # confirm non-existence
  on.exit(unlink(temp_dir, recursive = TRUE), add = TRUE)
  
  sl <- structure(list(list(scenario_number = 1)), class = "scenario_list")
  
  res <- saveScenarios(sl, save_path = temp_dir)
  
  expect_true(dir.exists(temp_dir))   # directory created
  expect_equal(res$path, temp_dir)
  
})  

#  Tests for print.scenario_list -----------------------------------------------
# TODO try to ensure the value contained in the objects are indeed the objects 
# being printed.

test_that("print.scenario_list header is correct and shows cohort count", {
  n_subjects <- c(5, 6)
  rr1 <- c(0.1, 0.2)
  rr2 <- c(0.3, 0.4)
  
  scenarios <- simulateScenarios(
    n_subjects_list     = list(n_subjects, n_subjects),
    response_rates_list = list(rr1, rr2),
    scenario_numbers    = c(1, 2),
    n_trials            = 3
  )
  
  # Pluralization + cohort count
  expect_output(print(scenarios), "scenario_list of 2 scenarios with 2 cohorts")
  expect_output(print(scenarios), "  - scenario_1", fixed = FALSE)
  expect_output(print(scenarios), "  - scenario_2", fixed = FALSE)
})


test_that("print.scenario_list prints table row labels", {
  n_subjects <- c(7, 8, 9)
  rr <- c(0.2, 0.3, 0.4)
  
  scenarios <- simulateScenarios(
    n_subjects_list     = list(n_subjects),
    response_rates_list = list(rr),
    scenario_numbers    = 1,
    n_trials            = 2
  )
  
  expect_output(print(scenarios), "true response rates:")
  expect_output(print(scenarios), "average number of subjects:")
})

test_that("print.scenario_list uses cohort column names c_1, c_2, ...", {
  n_subjects <- c(7, 8, 9)
  rr <- c(0.2, 0.3, 0.4)
  
  scenarios <- simulateScenarios(
    n_subjects_list     = list(n_subjects),
    response_rates_list = list(rr),
    scenario_numbers    = 1,
    n_trials            = 2
  )
  
  expect_output(print(scenarios), "\\bc_1\\b")
  expect_output(print(scenarios), "\\bc_2\\b")
  expect_output(print(scenarios), "\\bc_3\\b")
})

test_that("print.scenario_list prints footer lines with realizations info", {
  n_subjects <- c(10, 10)
  rr <- c(0.1, 0.2)
  
  scenarios <- simulateScenarios(
    n_subjects_list     = list(n_subjects),
    response_rates_list = list(rr),
    scenario_numbers    = 1,
    n_trials            = 5
  )
  
  expect_output(print(scenarios), "5 trial realizations per scenario")
  expect_output(print(scenarios), "unique trial realizations overall")
})

#  Tests for loadScenarios_list ------------------------------------------------

# TODO use SIMULATE SCENARIO - DONE

test_that("loadScenarios loads saved scenarios and returns proper class/names", {
  # Prepare a temp directory and two simple scenarios
  temp_dir <- tempfile()
  dir.create(temp_dir)
  
  scenario_list_to_save <- simulateScenarios(
    n_subjects_list     = list(c(10, 20, 30), c(10, 20, 30)),
    response_rates_list = list(c(0.1, 0.2, 0.3), c(0.5, 0.6, 0.7)),
    scenario_numbers    = c(1, 2),
    n_trials            = 5
  )
  
  # Reuse your saveScenarios to generate the RDS files
  save_info <- saveScenarios(scenario_list_to_save, save_path = temp_dir)
  
  # Load them back
  loaded <- loadScenarios(c(1, 2), load_path = temp_dir)
  
  # Class and names
  expect_s3_class(loaded, "scenario_list")
  
  # TODO only test required here - DONE
  expect_equal(loaded, scenario_list_to_save)
  
  # Clean up
  unlink(temp_dir, recursive = TRUE, force = TRUE)
})

# TODO test for other possible invalid inputs - DONE
test_that("loadScenarios points out invalid paths", {
  # Multiple paths (vector)
  expect_error(loadScenarios(1L, load_path = c(tempdir(), tempdir())), "load_path")
  
  # Numeric instead of string
  expect_error(loadScenarios(1L, load_path = 123), "load_path")
  
  # NULL
  expect_error(loadScenarios(1L, load_path = NULL), "load_path")
  
  # NA
  expect_error(loadScenarios(1L, load_path = NA_character_), "load_path")
  
  # Empty string
  #expect_error(loadScenarios(1L, load_path = ""), "load_path")
})

test_that("loadScenarios errors when files do not exist", {
  temp_dir <- tempfile()
  dir.create(temp_dir)
  
  # No files written -> should error when trying to read
  expect_error(suppressWarnings(loadScenarios(c(999)), load_path = temp_dir))
  
  unlink(temp_dir, recursive = TRUE, force = TRUE)
})

#  Tests for is.scenario_list -------------------------------------------------

test_that("is.scenario_list returns TRUE for valid input and FALSE otherwise", {
  # Valid scenario_list
  mock_scenario <- function(num) {
    structure(list(scenario_number = num), class = "scenario")
  }
  valid_list <- list(mock_scenario(1), mock_scenario(2))
  class(valid_list) <- "scenario_list"
  
  expect_true(is.scenario_list(valid_list))
  
  # Invalid cases
  expect_false(is.scenario_list(list()))
  expect_false(is.scenario_list("not a scenario list"))
  expect_false(is.scenario_list(NULL))
})


test_that("is.scenario_list errors when argument x is missing", {
  expect_error(
    is.scenario_list(),
    "Please provide an object for the argument 'x'"
  )
})


# Tests for createTrial --------------------------------------------------------

test_that("createTrial returns trial object with valid input", {
  with_mocked_bindings({
    result <- createTrial(n_subjects = c(10, 20), n_responders = c(5, 15))
    expect_true(!is.null(result))
  }, simulateScenarios = function(n_subjects_list, response_rates_list, n_trials) {
    list(trial = "mocked_trial")
  })
})

test_that("createTrial errors with invalid input", {
  expect_error(createTrial(n_subjects = c(10, NA), 
                           n_responders = c(5, 15)), "n_subjects")
  
  expect_error(createTrial(n_subjects = c(10, 20), 
                           n_responders = c(5.5, 15)), "n_responders")
})


# Tests for continueRecruitment ------------------------------------------------

test_that("Error is thrown if n_subjects_add_list is missing", {
  expect_error(
    continueRecruitment(
      decisions_list = list(scenario_1 = list(decisions_list = list()))
    ),
    "n_subjects_add_list"
  )
})

test_that("Error is thrown if decisions_list is missing", {
  expect_error(
    continueRecruitment(
      n_subjects_add_list = list(10)
    ),
    "decisions_list"
  )
})

test_that("Error is thrown if decisions_list is not of class 'decision_list'", {
  expect_error(
    continueRecruitment(
      n_subjects_add_list = list(10),
      decisions_list = list()
    ),
    "decisions_list"
  )
})

# Tests
test_that("Error for invalid method_name", {
  expect_error(
    continueRecruitment(
      n_subjects_add_list = list(c(10, 10)),
      decisions_list      = decisions,
      method_name         = "invalid_method"
    )
  )
})

test_that("Error when method_name is NULL and multiple methods are present", {
  decisions$scenario_1$analysis_data$analysis_parameters$method_names <- c("berry", "exnex")
  decisions$scenario_1$decisions_list <- list(berry = data.frame(), exnex = data.frame())
  
  expect_error(
    continueRecruitment(
      n_subjects_add_list = list(c(10, 10)),
      decisions_list      = decisions
    )
  )
})

test_that("Error is thrown if n_subjects_add_list and decisions_list lengths do not match", {
  
  expect_error(
    continueRecruitment(
      n_subjects_add_list = list(10, 20),
      decisions_list = decisions_list,
      method_name = "berry"
    )
  )
})

test_that("Error when selected method_name not analyzed in scenario", {
  
  # Restrict scenario to only 'berry' so 'exnex' is not analyzed
  decisions$scenario_1$analysis_data$analysis_parameters$method_names <- "berry"
  decisions$scenario_1$decisions_list <- list(berry = data.frame())
  
  expect_error(
    continueRecruitment(
      n_subjects_add_list = list(c(10, 10)),
      decisions_list      = decisions,
      method_name         = "exnex"  # not analyzed in this scenario
    ),
    "Selected method_name not analyzed"
  )
})

test_that("Error when response rate <=0 or >=1", {
  
  decisions$scenario_1$analysis_data$analysis_parameters$method_names <- "berry"
  decisions$scenario_1$decisions_list <- list()  # not used before error
  decisions$scenario_1$scenario_data$response_rates <- 
    matrix(c(0, 1), nrow = 1, dimnames = list(NULL, c("rr_hist1", "rr_hist2")))
  decisions$scenario_1$scenario_data$n_trials <- 1
  decisions$scenario_1$scenario_data$n_responders <- 
    matrix(c(0, 1), nrow = 1, dimnames = list(NULL, c("rr_hist1", "rr_hist2")))
  decisions$scenario_1$scenario_data$n_subjects <- 
    matrix(c(0, 1), nrow = 1, dimnames = list(NULL, c("rr_hist1", "rr_hist2")))
  decisions$scenario_1$scenario_data$scenario_number <- 1
  
  expect_error(
    continueRecruitment(
      n_subjects_add_list = list(c(10, 10)),
      decisions_list      = decisions,
      method_name         = "berry"
    ),
    "Only historical cohorts in scenario 1"
  )
})

test_that("Error when n_subjects_add length does not match recruiting cohorts", {
  
  # Override to simulate two recruiting cohorts and one historical
  decisions$scenario_1$analysis_data$analysis_parameters$method_names <- "berry"
  decisions$scenario_1$decisions_list <- list(berry = data.frame())
  decisions$scenario_1$scenario_data$response_rates <- 
    matrix(c(0.3, 0.4, 1), nrow = 1, dimnames = list(NULL, c("rr_A", "rr_B", "rr_hist")))
  
  # Provide only one addition value though two recruiting cohorts exist
  expect_error(
    continueRecruitment(
      n_subjects_add_list = list(c(10)),  # should be length 2
      decisions_list      = decisions,
      method_name         = "berry"
    )
  )
})

test_that("Only overall==TRUE rows are updated", {
  decisions$scenario_1$scenario_data$response_rates <- 
    matrix(c(0.5, 1), nrow = 1, dimnames = list(NULL, c("rr_A", "rr_hist")))
  
  decisions$scenario_1$scenario_data$n_subjects <- 
    matrix(c(0, 1), nrow = 1, dimnames = list(NULL, c("rr_A", "rr_hist")))
  
  decisions$scenario_1$scenario_data$n_responders <- 
    matrix(c(0, 1), nrow = 1, dimnames = list(NULL, c("rr_A", "rr_hist")))
  
  decisions$scenario_1$decisions_list <- list(berry = data.frame(decision_1 = TRUE, decision_2 = TRUE, overall = TRUE))
  decisions$scenario_1$analysis_data$analysis_parameters$method_names <- "berry"
  
  testthat::with_mocked_bindings(
    getScenario = function(n_subjects, response_rates, cohort_names, n_trials) {
      list(
        n_subjects   = matrix(10, nrow = 1, dimnames = list(NULL, cohort_names)),
        n_responders = matrix(5, nrow = 1, dimnames = list(NULL, cohort_names))
      )
    }, {
      out <- continueRecruitment(
        n_subjects_add_list = list(c(10)),
        decisions_list      = decisions,
        method_name         = "berry"
      )
      
      # TODO set seed for the responders in set up file - DONE
      expect_equal(unname(out$scenario_1$n_subjects[, "rr_A"]), 10)
      expect_equal(unname(out$scenario_1$n_responders[, "rr_A", drop = TRUE]), 5)
      expect_equal(unname(out$scenario_1$n_subjects[, "rr_hist"]), 1)
      expect_equal(unname(out$scenario_1$n_responders[, "rr_hist", drop = TRUE]), 1)
    }
  )
})
